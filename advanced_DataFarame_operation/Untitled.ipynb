{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dad64c4b-1bab-4ca7-9478-20a2a1fc7c58",
   "metadata": {},
   "source": [
    "## Advanced DataFrame Operations\n",
    "When working with real-world data, it is common to encounter multiple datasets that need to be combined, split, or reshaped. Pandas offers several powerful methods to perform these operations efficiently. Understanding how to manipulate data at this level is essential for building robust data analysis workflows.\n",
    "\n",
    "In this module, we will cover following methods:\n",
    "\n",
    "- Merging DataFrames\n",
    "- Concatenating DataFrames\n",
    "-Joining DataFrames\n",
    "- Reshaping DataFrames\n",
    "- Stacking and Unstacking\n",
    "- Pivoting and Melting Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c173e78c-1b89-401c-aa80-21fddfc3e842",
   "metadata": {},
   "source": [
    "### 1 Merging DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03dcb182-329e-41c1-8a03-ac2143b45206",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "183d8cec-97c5-4a66-8262-1352c8fa0039",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create two sample DataFrames\n",
    "df1 = pd.DataFrame({\n",
    "    'ProductID': [101, 102, 103],\n",
    "    'SalesAmount': [200, 150, 400]\n",
    "})\n",
    "\n",
    "df2 = pd.DataFrame({\n",
    "    'ProductID': [102, 103, 104],\n",
    "    'Region': ['North', 'South', 'East']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f1c8ba7-3735-4333-a844-92577f36d00c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ProductID  SalesAmount Region\n",
      "0        102          150  North\n",
      "1        103          400  South\n"
     ]
    }
   ],
   "source": [
    "merge_data = pd.merge(df1, df2, on='ProductID', how='inner')\n",
    "print(merge_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5531e77f-e4ee-44ff-b379-48f8a662af81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ProductID  SalesAmount Region\n",
      "0        101          200    NaN\n",
      "1        102          150  North\n",
      "2        103          400  South\n"
     ]
    }
   ],
   "source": [
    "merge_data_left = pd.merge(df1, df2, on='ProductID', how='left')\n",
    "print(merge_data_left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d90bb216-a9cd-4ec6-80a3-ee68db3ce3d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ProductID  SalesAmount Region\n",
      "0        102        150.0  North\n",
      "1        103        400.0  South\n",
      "2        104          NaN   East\n"
     ]
    }
   ],
   "source": [
    "merge_data_rigth = pd.merge(df1, df2, on='ProductID', how='right')\n",
    "print(merge_data_rigth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "122b09cf-88d8-4ad1-b72d-0a9f1e4cf9c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ProductID  SalesAmount Region\n",
      "0        101        200.0    NaN\n",
      "1        102        150.0  North\n",
      "2        103        400.0  South\n",
      "3        104          NaN   East\n"
     ]
    }
   ],
   "source": [
    "merge_data_outter = pd.merge(df1, df2, on='ProductID', how='outer')\n",
    "print(merge_data_outter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7e8500-aedb-468e-84c4-70945d23703d",
   "metadata": {},
   "source": [
    "## Concatenating DataFrames\n",
    "\n",
    "Concatenation is the process of appending or stacking DataFrames either along rows (vertical concatenation) or along columns (horizontal concatenation). This operation is done using the `concat()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa5d8779-b0a4-4619-8679-cf48c43d793d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data farame \n",
    "df3 = pd.DataFrame({\n",
    "    'ProductID': [105, 106],\n",
    "    'SalesAmount': [250, 350]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0394afa9-f318-4941-a049-dac1293b4396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ProductID  SalesAmount\n",
      "0        101          200\n",
      "1        102          150\n",
      "2        103          400\n",
      "3        105          250\n",
      "4        106          350\n"
     ]
    }
   ],
   "source": [
    "# concatinate df1 and df3vertically\n",
    "# we use ignore_index to make sure that we get a new sequential index\n",
    "\n",
    "df_concatenated = pd.concat([df1, df3], ignore_index=True)\n",
    "print(df_concatenated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "410e2fd6-cd18-47c5-a4d2-70e2c112727a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ProductID  SalesAmount  ProductID Region\n",
      "0        101          200        102  North\n",
      "1        102          150        103  South\n",
      "2        103          400        104   East\n"
     ]
    }
   ],
   "source": [
    "# concantenate df1, df2 horizontally\n",
    "df_hz = pd.concat([df1, df2], axis=1)\n",
    "print(df_hz)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d88ba0-b6f7-41e3-a1f6-f4276bcd1eb5",
   "metadata": {},
   "source": [
    "Here, `axis=1` specifies that the DataFrames should be concatenated along columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f46417-9ae2-4c74-8186-2348607c4ceb",
   "metadata": {},
   "source": [
    "## Joining DataFrames\n",
    "\n",
    "The `join()` function is similar to merge() but works with indices. It’s a convenient method when you need to join DataFrames based on their index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42db1d45-2b12-4501-b57d-ab2e26af5143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           SalesAmount Region\n",
      "ProductID                    \n",
      "102                150  North\n",
      "103                400  South\n"
     ]
    }
   ],
   "source": [
    "# set ProductID as the index for both DataFrame\n",
    "df1.set_index('ProductID', inplace=True)\n",
    "df2.set_index('ProductID', inplace=True)\n",
    "# join df1, df2 based on their indicies\n",
    "\n",
    "df_joined = df1.join(df2, how='inner')\n",
    "print(df_joined)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b4c785-846a-4525-94fd-d394259f33b6",
   "metadata": {},
   "source": [
    "## Reshaping DataFrames\n",
    "\n",
    "Reshaping data allows you to change the layout or structure of your DataFrame, which is especially useful when preparing data for analysis or visualization. Pandas provides several methods for\n",
    "\n",
    "reshaping DataFrames, including pivoting, melting, stacking, and unstacking.\n",
    "\n",
    "Pivoting Data\n",
    "\n",
    "Pivoting reshapes the DataFrame by turning unique values from one column into separate columns. It’s commonly used to summarize data and display it in a more compact form.\n",
    "\n",
    "The `pivot()` function is used to create a new table where a column’s unique values become new columns, and you can set other columns as the index and values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25dd7936-115f-4f89-8f5f-ec539eb4a939",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"Date\": [\"2024-01-01\", \"2024-01-01\", \"2024-01-02\", \"2024-01-02\"],\n",
    "    \"Product\": [\"A\", \"B\", \"A\", \"B\"],\n",
    "    \"SalesAmount\": [100, 200, 150, 250]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1672c962-2011-46ee-8e2e-6eca71ec78a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date Product  SalesAmount\n",
      "0  2024-01-01       A          100\n",
      "1  2024-01-01       B          200\n",
      "2  2024-01-02       A          150\n",
      "3  2024-01-02       B          250\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c074d2ff-5e37-4005-95e7-3222af6b7c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product       A    B\n",
      "Date                \n",
      "2024-01-01  100  200\n",
      "2024-01-02  150  250\n"
     ]
    }
   ],
   "source": [
    "# pivot the DataFrame\n",
    "df_pivot = df.pivot(index='Date', columns='Product', values='SalesAmount')\n",
    "print(df_pivot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce30cd20-58ce-4603-9543-ddee7b62d9ce",
   "metadata": {},
   "source": [
    "## Melting Data\n",
    "\n",
    "The opposite of pivoting is melting, which transforms a DataFrame from wide format (with multiple columns) to long format. The `melt()` function is useful when you want to convert columns into rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b2fd5a0-8df2-4da2-8489-34b897394a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date SalesAmount  value\n",
      "0  2024-01-01           A    100\n",
      "1  2024-01-02           A    150\n",
      "2  2024-01-01           B    200\n",
      "3  2024-01-02           B    250\n"
     ]
    }
   ],
   "source": [
    "# melting the pivoted data into a long format \n",
    "df_long_format = pd.melt(df_pivot.reset_index(), id_vars='Date', value_vars=['A', 'B'], var_name='SalesAmount')\n",
    "print(df_long_format)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563745c5-a6a7-41c3-9695-7ef9d9acc3dc",
   "metadata": {},
   "source": [
    "## Stacking and Unstacking\n",
    "\n",
    "Stacking and unstacking are used to reshape DataFrames by moving the innermost columns to become the innermost row index (stacking) or moving the innermost row index to become the innermost columns (unstacking). These operations are particularly useful for working with hierarchical or multi-level indices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502f27ae-8d00-4456-9e7f-405b4c532ff2",
   "metadata": {},
   "source": [
    "## Stacking Single-Level Columns\n",
    "\n",
    "Stacking moves the column labels into rows, effectively \"compressing\" the DataFrame. This is useful when working with DataFrames that have simple column structures, such as single-level columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0c3bf42b-e348-4b31-88f3-544a8ebfc8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mult = pd.DataFrame(\n",
    "    {\n",
    "        ('Region', 'North'): [200, 300],\n",
    "        ('Region', 'South'): [150, 400]\n",
    "    },\n",
    "    index=['Poduct1', 'Product2']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "969da9bd-84ef-404c-8795-17d371cb0e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Region      \n",
      "          North South\n",
      "Poduct1     200   150\n",
      "Product2    300   400\n"
     ]
    }
   ],
   "source": [
    "print(df_mult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6751feb5-4a6a-4107-861a-81c1672e512b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Region\n",
      "Poduct1  North     200\n",
      "         South     150\n",
      "Product2 North     300\n",
      "         South     400\n"
     ]
    }
   ],
   "source": [
    "# stack the dataframedf\n",
    "df_stacked = df_mult.stack()\n",
    "print(df_stacked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1a16a500-3796-42cd-9319-fe19008dbd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_muti = pd.DataFrame(\n",
    "    {\n",
    "        ('SalesAmount', 'North'): [200, 300],\n",
    "        ('SalesAmount', 'South'): [150, 400]\n",
    "        \n",
    "    },\n",
    "    index=['Product1', 'Product2']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "98415b87-fd75-4d04-8463-0c622e1f9b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stacked1 = df_muti.stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dd4f7d84-e56c-42cd-a40d-8cd65a078cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                SalesAmount\n",
      "Product1 North          200\n",
      "         South          150\n",
      "Product2 North          300\n",
      "         South          400\n"
     ]
    }
   ],
   "source": [
    "print(df_stacked1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8793ff1b-3f10-4c67-88b8-38e9dc1f266d",
   "metadata": {},
   "source": [
    "## Unstacking Data\n",
    "\n",
    "Unstacking is the reverse of stacking. It moves the innermost level of the index to become the innermost columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "53bc85ad-8844-46ca-8fa0-70a95a2d0b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         SalesAmount      \n",
      "               North South\n",
      "Product1         200   150\n",
      "Product2         300   400\n"
     ]
    }
   ],
   "source": [
    "df_unstacked = df_stacked1.unstack()\n",
    "print(df_unstacked)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d8ed0b-a635-4447-8e85-cc8fee9b91e2",
   "metadata": {},
   "source": [
    "## Pivot Table\n",
    "The pivot_table() function is an extension of pivot() that allows you to aggregate data while reshaping it. It’s similar to Excel’s pivot table functionality and is especially useful for summarizing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5d066c7f-99a4-4c21-a4df-d5d86fc4f622",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Region'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# create a pivot_tabe with aggregatoin\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m df_pivot_tabe \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpivot_table\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSalesAmount\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mProduct\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRegion\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maggfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msum\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/reshape/pivot.py:97\u001b[0m, in \u001b[0;36mpivot_table\u001b[0;34m(data, values, index, columns, aggfunc, fill_value, margins, dropna, margins_name, observed, sort)\u001b[0m\n\u001b[1;32m     94\u001b[0m     table \u001b[38;5;241m=\u001b[39m concat(pieces, keys\u001b[38;5;241m=\u001b[39mkeys, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m table\u001b[38;5;241m.\u001b[39m__finalize__(data, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpivot_table\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 97\u001b[0m table \u001b[38;5;241m=\u001b[39m \u001b[43m__internal_pivot_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m    \u001b[49m\u001b[43maggfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmargins\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmargins_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m table\u001b[38;5;241m.\u001b[39m__finalize__(data, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpivot_table\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/reshape/pivot.py:166\u001b[0m, in \u001b[0;36m__internal_pivot_table\u001b[0;34m(data, values, index, columns, aggfunc, fill_value, margins, dropna, margins_name, observed, sort)\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(values)\n\u001b[0;32m--> 166\u001b[0m grouped \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m agged \u001b[38;5;241m=\u001b[39m grouped\u001b[38;5;241m.\u001b[39magg(aggfunc)\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dropna \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(agged, ABCDataFrame) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(agged\u001b[38;5;241m.\u001b[39mcolumns):\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/frame.py:8252\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m   8249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have to supply one of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mby\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   8250\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis_number(axis)\n\u001b[0;32m-> 8252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameGroupBy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   8253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8255\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mas_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8258\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8259\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8260\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8261\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8262\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/groupby/groupby.py:931\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropna \u001b[38;5;241m=\u001b[39m dropna\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 931\u001b[0m     grouper, exclusions, obj \u001b[38;5;241m=\u001b[39m \u001b[43mget_grouper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    932\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    933\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    934\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    935\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    936\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    937\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    938\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    939\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    941\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj \u001b[38;5;241m=\u001b[39m obj\n\u001b[1;32m    942\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_get_axis_number(axis)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/groupby/grouper.py:985\u001b[0m, in \u001b[0;36mget_grouper\u001b[0;34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[0m\n\u001b[1;32m    983\u001b[0m         in_axis, level, gpr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, gpr, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    984\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 985\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(gpr)\n\u001b[1;32m    986\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gpr, Grouper) \u001b[38;5;129;01mand\u001b[39;00m gpr\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    987\u001b[0m     \u001b[38;5;66;03m# Add key to exclusions\u001b[39;00m\n\u001b[1;32m    988\u001b[0m     exclusions\u001b[38;5;241m.\u001b[39madd(gpr\u001b[38;5;241m.\u001b[39mkey)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Region'"
     ]
    }
   ],
   "source": [
    "# create a pivot_tabe with aggregatoin\n",
    "\n",
    "df_pivot_tabe = pd.pivot_table(df, values='SalesAmount', index='Product', columns='Region', aggfunc='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1b703226-694e-413f-8cba-5ce012c26469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date Product  SalesAmount\n",
      "0  2024-01-01       A          100\n",
      "1  2024-01-01       B          200\n",
      "2  2024-01-02       A          150\n",
      "3  2024-01-02       B          250\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
